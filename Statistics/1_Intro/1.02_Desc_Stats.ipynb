{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistics\n",
    "## Chapter 1.2 - Descriptive Statistics\n",
    "\n",
    "Data by itself is useless. We need to transform the data so it can be analyzed and understood by people. Graphical transforms are great way to visualizing and understanding the data. 2 simple and commonly used graphical representation are a histograms and scatter plots. Graphs are great starting point for data analysis, but we cannot \"do math\" on graphs. Descriptive statistics are numberic values that quantify/ describes the features of the graphs so we can do rigorous, mathematical data analysis. It is important to note the equations for these values calculated from a sample. The theoretical definitions/ equations will be covered later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "- Population\n",
    "    - The group of people, items, or events that is related to the question of interest\n",
    "- Sample\n",
    "    - A subset of the population that we have data for\n",
    "- Statistic\n",
    "    - A value computed from the data\n",
    "- Outlier\n",
    "    - A data value that is significantly different from the rest of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "- sample statistic\n",
    "    - Typically, it uses the same symbol as the theoretical statistic expect it has an extra \"hat\" (^) above it\n",
    "    - e.g. $\\hat{\\sigma}$, $\\hat{\\sigma}^2$, $\\hat{\\beta}$\n",
    "- sample mean\n",
    "    - Most notable expection to the sample statistic notation\n",
    "    - Usually notated with a \"bar\" (-) above the corresponding random variable symbol. \n",
    "    - e.g. $\\bar Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of Central Tendency\n",
    "Central tendency is the center value or typical value of the data. The 3 most commonly used ones are: (arithmetic) mean, median, and mode.\n",
    "\n",
    "### Mean  \n",
    "The mean (or average) is defined as the sum of the data divided by the number of data.\n",
    "- (1) $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$\n",
    "\n",
    "### Median \n",
    "The median is defined as the value where 50% of the data is greater than or equal to it.\n",
    "- $\\hat y_{median} = $ middle number of the ordered values  \n",
    "\n",
    "If the number of data is odd, then the middle number is the median. If the number of data is even, then the average of the 2 middle number is the median.\n",
    "\n",
    "### Mode\n",
    "The mode is defined as the value with the highest frequency.\n",
    "- $\\hat y_{mode} = $ most common number\n",
    "\n",
    "There may be more than 1 mode in the data.\n",
    "\n",
    "### Comparison\n",
    "When it comes to outliers, median and mode are more robust to outliers. This is because a large outlier can significantly change the mean, but it will hardly affect the median or the mode. However, mean has better mathematical properties, such as being differentiable.  \n",
    "\n",
    "Which one is the best depends on the situation. Typically mean is preferred because outliers can be removed from the data set and it has superior mathematical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of Variability/ Dispersion\n",
    "\n",
    "This is measure of how spread apart is the data/ histogram. \n",
    "\n",
    "### Variance and Standard Deviation \n",
    "Variance is defined as the following:\n",
    "- (2) variance = $\\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^n(y_i-\\bar{y}^2)$\n",
    "\n",
    "Standard deviation is the square root of the variance\n",
    "- (3) standard deviation = $\\sigma = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n(y_i-\\bar{y}^2)}$\n",
    "\n",
    "### Range\n",
    "Range is defined to be the difference between the maximum and minimun value of the dataset.\n",
    "- range = $max(y_1, y_2, ..., y_n) - min(y_1, y_2, ..., y_n)$\n",
    "\n",
    "### Interquartile range\n",
    "The nth percentile is the number that is greater than or equal to n% of the dataset. Quantile is percentile divided by 100, in other words the same thing but n% is written in decimal form.\n",
    "\n",
    "A quartile splits the dataset into 4 equal segments. The 1st quartile or lower quartile (Q1) is defined to 25th percentile. The 2nd quartile (Q2) or median is defined to be the 50th percentile. The 3rd quartile or upper quartile (Q3) is defined to be the 75 percentile. Sometimes 0th and 4th quartile considered to be the smallest and largest value in the dataset,  respectively.\n",
    "\n",
    "The Interquartile range (IQR) is defined to be the difference between the 3rd and 1st quartile.\n",
    "- IQR = $Q3 - Q1$\n",
    "\n",
    "### Comparison\n",
    "IQR is the most robust to outliers, followed by variance/ standard deviation, and finally range. However, variance  has the best mathematical properties since it is differentiable. \n",
    "\n",
    "Typically, variance is the preferred due to the fact it is differentiable. After doing math using the variance, I typically converted it into standard deviation because it is easier to intrept.\n",
    "\n",
    "### Shape of Histogram\n",
    "There are statistic that describe the shape of the histogram: skewness and kurtosis. It can be though of as discribing how uneven is the spread of the data. We will not cover how to calculated skewness and kurtosis will not be covered at all.\n",
    "\n",
    "Skewness refers to if the histogram has long left tail, right tail, or symmetric. If it has a long left tail, then is it said to be skewed-left or negative skew. If it has a long right tail, then it is said to be skewed-right or positive skew. If it has no tail, then it is said to be symmetric or 0 skew. When it is skewed-left, then $y_{mode}> y_{median} > y_{mean}$. When it is skewed-right, then $y_{mode} < y_{median} < y_{mean}$. When it is skewed-right, then $y_{mode} \\approx y_{median} \\approx y_{mean}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Correlation\n",
    "They are both measure how linearly dependant are the 2 variables. In other words, this measures how tight of a line does the scatter plot make. The sample covariance is defined as the following:\n",
    "- (4) covariance = $\\hat {Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^n [(x_i-\\bar{x})(y_i-\\bar{y})]$\n",
    "\n",
    "Correlation is the covariance divided by the standard deviation of the 2 variables.\n",
    "- (5) correlation = $\\hat {Cor}(X,Y) = \\frac{\\hat {Cov}(X, Y)}{\\hat\\sigma_X \\hat\\sigma_Y}$\n",
    "    - $\\sigma_X$ is the standard deviation for $X$\n",
    "    - $\\sigma_Y$ is the standard deviation for $Y$\n",
    "\n",
    "This has the effect of normalizing the covariance to be between -1 and 1. A positive sign for the correlation corresponds the 2 variables having a positive relationship, and a negative sign corresponds to a negative relationship. The closer the magnitude of the correlation is to 1, the stronger linear dependance is. It is important to note that no part of covariance or correlation indicate the slope of the line.\n",
    "\n",
    "Typically, covariance is used for calculations because it is differentiable, then converted to correlation for interepation.\n",
    "\n",
    "It is important to note that covariance and correlation only measures the strength of the linear relationship, not overall relationship. If the 2 variables has a strong nonlinear relationship (like a quadratic relationship), the covariance and correlation will still give a value. This value is not a good measure of nonlinear relationship and should be used with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation\n",
    "1) mean = $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$  \n",
    "2) variance = $\\hat \\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^n(y_i-\\bar{y}^2)$  \n",
    "3) standard deviation = $\\hat \\sigma = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n(y_i-\\bar{y}^2)}$  \n",
    "4) covariance = $\\hat {Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^n [(x_i-\\bar{x})(y_i-\\bar{y})]$  \n",
    "5) correlation = $\\hat {Cor}(X,Y) = \\frac{Cov(X, Y)}{\\sigma_X \\sigma_Y}$  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}