{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistics\n",
    "## Chapter 1.4 - Discrete Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "- Probability distribution\n",
    "    - A mathematical function that models/ describes the probability of a result occuring\n",
    "    - The probability that the random variable $X$ takes on the value $x$, $P(X=x)$\n",
    "        - The function is normally defined using an equation, but it could be defined using anything as 1 input corresponds to 1 output (such as a table or a histogram)\n",
    "\n",
    "## Notation\n",
    "- Events with random variable\n",
    "    - The event can be defined using random variables, a particular outcome, and inequalities\n",
    "    - e.g. $X=9, X\\le9, X=x, X\\le x$\n",
    "- Probability with random variable\n",
    "    - Instead of defining an event with a predefined set, we define an event inside the parentheses.\n",
    "    - e.g. $P(X = 9)$, $P(X \\le 9)$, $P(X = x)$, $P(X \\le x)$\n",
    "    - $P(X = x)$ will sometimes be shorten to $p(x)$ or $p_X(x)$\n",
    "- Probability distribution\n",
    "    - $P(X = x)$,  $p(x)$, or $p_X(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Mass Function\n",
    "The probability distribution of a descrete random variable is also called a probability mass function (pmf). Typically, we will explicitly define the regions where the probability is $>0$. Everything that is not explicitly defined is assumed to have a probability of $0$. \n",
    "\n",
    "Recall the axioms of probability:\n",
    "- $P(S) = 1$  \n",
    "- $P(A) \\ge 0$  \n",
    "- $P(S) = \\sum_{i=1}^n P(A_i)=1$, if $A_i$ are mutually exclusive for all $i$   \n",
    "\n",
    "Unsurprisingly, these also apply to the probability mass function. Lets define set $A$ to be events where $X = x$. Then using substitution, we get $P(X = x) \\le 1$. Lets define $A_i$ to be events events $X = x_i$. Clearly these events are mutually exclusive because an outcome cannot have 2 different results. Then using substitution again, we get $\\sum_{x_i} P(X = x_i) = P(S) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Distribution Function\n",
    "\n",
    "The cumulative distribution function (cdf) is the probability the random variable $X$ is less than or equal to a particular value $x$, and is typically denoted as $F(x)$. The cdf also just so happens to model the quantile of the distribution.\n",
    "- $F(x)=P(X \\le x)$\n",
    "\n",
    "We can also use the cdf to calculate the probability of $X$ being between the intervals $[x_1, x_2]$\n",
    "- $F(x_2) - F(x_1) = P(x_1 \\le X \\le x_2)$\n",
    "    - $F(x_2) - F(x_1) = P(X \\le x_2) - P(X \\le x_1) = P(x_1 \\le X \\le x_2)$\n",
    "\n",
    "To calculate the cdf for a discrete random variable, you would calculate all of the pmfs from $-\\infty$ to $x$ and add them together\n",
    "- $F(x)=P(X \\le x) = \\sum _{y \\le x} p(y)$ \n",
    "\n",
    "Using the properties of a pmf, we can derive the properties of a cdf.\n",
    "- $\\lim_{x \\to -\\infty} F(x) = 0$\n",
    "    - No numerical result can have a value of $\\le -\\infty$. So if the set of events where $X \\le -\\infty$ must be the empty set.\n",
    "- $\\lim_{x \\to \\infty} F(x) = 1$\n",
    "    - All numerical result must have a value of $\\le -\\infty$. So if the set of events where $X \\le \\infty$ must be the entire sample space.\n",
    "- If $x_1 < x_2$, then $F(x_1) \\le F(x_2)$\n",
    "    - $F(x)$ is a nondecreasing function.\n",
    "    - This is because $p(x) \\ge 0$ for all values of $x$. It is impossible to decrease the cdf by adding more numbers $\\ge0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "Expected value is the theoretically mean for a probability distribution. You can think about it as the mean of the population. This is normally notated with a $E$ followed by the random variable in parenthese, e.g. $E(X)$, or the greek symbol mu, $\\mu$. The equation for expected value of a probability mass function is the following:\n",
    "- (1) $E(X) =\\mu= \\sum_x xP(X=x)$\n",
    "\n",
    "Lets see how this relates to the mean equation.\n",
    "- expected value equation\n",
    "    - $E(X) = \\sum_x xp(x)$  \n",
    "- rewrite $p(x)$ using the probability equation\n",
    "    - $= \\sum_x x\\frac{|X=x|}{|S|}$\n",
    "- move $|S|$ outside the summation because it is a constant\n",
    "    - $= \\frac{1}{|S|} \\sum_x x|X=x|$\n",
    "        - $|X=x|$ can be intrepted as the number of times $X=x$ occurred\n",
    "        - $\\sum_x x|X=x|$ can be intrepted as grouping the results together and finding the sum of those first. Then summing everything together after.\n",
    "        - $\\frac{1}{|S|}$ can be intrepted as dividing everything by the total\n",
    "    - The overall intreptation is the same as the mean equation, sum up all of the results and dividing it by the total number of events. However, the expected value equation groups some of these answers before summing everything together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Expected Value\n",
    "The expected value of a probability distribution will always yield the same result. This is because expected value is a function of the entire population. Since the population for a given experiment stays the same, a function based on the entire population will always yield the same result. This differs from a function of random variables, such as sample mean $\\bar y$. This is because a random variable is based on a sample from the population. The sample may be different for different instances of the same experiemnt, meaning the sample has randomness. Functions of random variables also inherit this randomness, thus behaving like a random variable. \n",
    "\n",
    "### Equations\n",
    "- (2) $E(g(X)) = \\sum_x g(x)p(x)$\n",
    "    - You would think that $E(g(X)) = \\sum_x g(x)p(g(x))$\n",
    "    - $p(g(x)) = p(x)$\n",
    "        - This is because $x$ and the $g(x)$ are refering to the same event, but with different result values.\n",
    "- (3) $E(c) = c$\n",
    "    - $c$ is a constant\n",
    "- (4) $E(cX) = cE(X)$\n",
    "- (5) $E(X + Y) = E(X) + E(Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "The theoretical variance is normally notated as $Var$ or $V$ followed by the random variance in parenthese, e.g. $Var(X)$ or $V(X)$. The equation for the theoretical variance is defined as the following:\n",
    "- (6) $Var(X) = E[(X - \\mu)^2]$ \n",
    "    - Using equation 2, we can derive that $Var(X)= \\sum_x (x-\\mu)^2p(x)$\n",
    "    - Since $\\mu$ can be interpreted as the mean of the distribution. The variance equation can be interpreted as the average of the squared difference between the result and the mean. \n",
    "\n",
    "Since the difference is squared, the following must be true:\n",
    "- $Var(X) \\ge 0$\n",
    "\n",
    "We can also rearrange the equation into:\n",
    "- (7) $Var(X) = E(X^2) - \\mu^2 = \\sum_x x^2p(x) - \\mu^2$\n",
    "    - $Var(X) = E[(X - \\mu)^2] = E[X^2 - 2X\\mu + \\mu^2] = E(X^2) - E(2X\\mu) + E(\\mu^2)$\n",
    "        - Note: $\\mu$ is a constant\n",
    "    - $ = E(X^2) - 2\\mu E(X) + E(\\mu^2) = E(X^2) - 2\\mu^2 + E(\\mu^2) = E(X^2) - \\mu^2$\n",
    "- This is a useful property of variance, I don't think this has great interpretation value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Variance\n",
    "Similar to expected value, variance is a constant while sample variance is a random variable.\n",
    "\n",
    "### Equations\n",
    "- (8) $Var(c) = 0$\n",
    "    - $c$ is a constant\n",
    "- (9) $Var(X + c) = Var(X)$\n",
    "    - $Var(X+c) = E[(X+c - E(X+c))^2] = E[(X+c - E(X) - c)^2] = E[(X - E(X))^2] = Var(X)$\n",
    "    - This can be interpreted as the spread of the data staying the same\n",
    "- (10) $Var(aX) = a^2Var(X)$\n",
    "    - $Var(aX) = E[(aX - a\\mu)^2] = E[a^2(X - \\mu)^2] = a^2 E[(X - \\mu)^2] = a^2Var(X)$\n",
    "- (11) $Var(X + Y) = Var(X) + Var(Y)$, if $X$ and $Y$ are independent\n",
    "- (12) $Var(aX + bY) = a^2Var(X) + b^2Var(Y) + abCov(X, Y)$\n",
    "    - $Cov$ will be discussed in a later chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Random Variable\n",
    "The simplest experiment we can have is one with 2 possible outcomes. Typically, the outcomes are referred to as \"success\" and \"failure\", with \"success\" usually referring to the preferred outcome. Mathematically, the outcomes are encoded as 1 or 0 respectively. This type of random variable is called a Bernoulli random variable or a Bernoulli trail (name after Jacob Bernoulli). The remaining discrete random variables introduced in this chapter will be derived from the Bernoulli. Note: not all discrete random variables are based on the Bernoulli.\n",
    "\n",
    "Suppose probability of success, $P(X=1)$, is some constant $p$. Then $P(X=0)$ must be $1-p$ because it is the complement of $X=1$. We can combine them together to form the following pmf:\n",
    "- (13) $p(x) = \\begin{cases} p, \\quad \\text{if }x=1 \\\\ 1-p, \\quad \\text{if }x=0 \\end{cases}$  \n",
    "    - Sometimes also written as $p(x) = px + (1-p)(1-x)$ or $p(x) = p^x(1-p)^{1-x}$\n",
    "\n",
    "Using the pmf, we can derive the expected value and variance.  \n",
    "### Expected Value and Variance\n",
    "- (14) $E(X) = p$\n",
    "    - $E(X) = \\sum_x xp(x) = 0(1-p) + 1*p = p$  \n",
    "- (15) $Var(X) = p(1-p)$\n",
    "    - $Var(X) =\\sum_x (x-\\mu)^2p(x) = \\sum_x (x-p)^2p(x) = (1-p)^2p + (0-p)^2(1-p)$\n",
    "    - $= p - 2p^2 +p^3 + p^2 - p^3 = p - p^2 = p(1-p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial\n",
    "Binomial random variable models the number of successes in $n$ iid Bernoulli trials. \n",
    "\n",
    "iid means independent and identically distributed.\n",
    "- independent means the random variables are independent from each other\n",
    "- identically distributed means the random variables are from the same distribution or population\n",
    "\n",
    "Suppose the random variable $X$ above is a coin flipping experiment, with $X=1$ if the coin is heads and $X=0$ otherwise (sometimes shorten to o.w.). If we repeat the coin flipping experiment $n$ times, then we would generate a sequence of random variables, $X_1, X_2, X_3, ..., X_n$. These random variables are said to be independent because the outcome of one experiment will not effect the outcome of another, and identically distributed because we are using the same coin. We are assuming that the coin behavior does not change between experiments, therefore having the same probability distribution (same type of random variables with same parameters). Since success is encoded as a 1 for a Bernoulli, binomial can be seen as the sum of $n$ iid Bernoulli trials.\n",
    "\n",
    "It is fairly simple to derive the binomial pmf.\n",
    "- Given: $n$ number of Bernoulli trails, $x$ number of successes\n",
    "- We know that the probability of success for a Bernoulli is $p$. So the probability of x number of success is $p^x$.\n",
    "- We know that the probability of failure for a Bernoulli is $1-p$ and the number of failure is $n-x$. So the probability of $n-1$ number of failure is $(1-p)^{n-x}$.\n",
    "- There are many ways to have $x$ number of successes in $n$ trails. We can calculate the number of ways by using combinations, $\\binom nx$.\n",
    "\n",
    "By combining everything above, we have the following pmf:\n",
    "- (16) $p(x) = \\binom n x p^x (1-p)^{n-x}$, for $n \\in \\mathbb{N}, \\quad p \\in [0,1], \\quad x \\in \\{0, 1, 2, ..., n\\} $\n",
    "\n",
    "### Notation\n",
    "- $X \\sim B(n, p)$\n",
    "\n",
    "### Expected Value and Variance\n",
    "We could derive both of these from the pmf. However, it is significantly easier to derive them using a sequence of Bernoulli random variables, $Y_1, ..., Y_n$, instead.\n",
    "- (17) $E(X) = np$\n",
    "    - $E(X) = E(Y_1 + Y_2 + ... + Y_n) = E(Y_1) + ... + E(Y_n) = np$\n",
    "- (18) $Var(X) = np(1-p)$\n",
    "    - $Var(X) = Var(Y_1 + Y_2 + ... + Y_n) = Var(Y_1) + ... + Var(Y_n) = np(1-p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson\n",
    "\n",
    "Poisson (named after Siméon Denis Poisson) is used to model the number of times something occurs over a fixed length of time, area, or volume.\n",
    "\n",
    "Imagine we are trying to model the number of car accidents over a year. We can try to model this as a binomial. We can split the year into $n$ intervals, and each interval will be a Bernoulli trail on whether a car accident occurred. We cannot have multiple car accident during the same time intervals because then it wont be a Bernoulli. So we have to have $n=\\infty$ for the probability of multiple car accident during the same intervals be $0$. Now we have the following equation:\n",
    "- $\\lim_{n \\to \\infty} \\binom n x p^x (1-p)^{n-x}$  \n",
    "\n",
    "Now we have another problem, $p$ must equal $0$ or else $n*p$ (expected value of binomial) will blow up to $\\infty$. Setting $p=0$ will cause our pmf to collapse to 0. Lets set $\\lambda=np$. Then we can subsitute $p$ with $\\frac{\\lambda}{n}$.\n",
    "- $\\lim_{n \\to \\infty} \\binom n x \\Big( \\frac{\\lambda}{n}\\Big) ^x (1- ( \\frac{\\lambda}{n}) ^{n-x}$  \n",
    "\n",
    "We can simplify this to get our new pmf, the pmf of a Poisson:\n",
    "- (19) $p(x) = \\lim_{n \\to \\infty} \\binom n x \\frac{\\lambda}{n}^x (1-\\frac{\\lambda}{n})^{n-x} = \\frac{\\lambda^x e^\\lambda}{x!}$, for $\\lambda >0, \\quad x \\in \\mathbb{N}$\n",
    "    - $\\lim_{n \\to \\infty} \\binom n x \\Big( \\frac{\\lambda}{n}\\Big) ^x (1- \\Big( \\frac{\\lambda}{n})\\Big) ^{n-x} = \\lim_{n \\to \\infty} \\frac{n!}{(n-x)!x!} \\Big( \\frac{\\lambda}{n}\\Big) ^x (1-  \\frac{\\lambda}{n}) ^{n-x} = \\lim_{n \\to \\infty} \\frac{n!\\lambda^x}{(n-x)!x!n^x} \\lim_{n \\to \\infty} (1-  \\frac{\\lambda}{n}) ^{n-x}$\n",
    "        - $\\lim_{n \\to \\infty} (1-  \\frac{\\lambda}{n}) ^{n-x} = \\lim_{n \\to \\infty} (1-  \\frac{\\lambda}{n}) ^{n} = e^{-\\lambda}$\n",
    "    - $= \\lim_{n \\to \\infty} \\frac{n!\\lambda^x}{(n-x)!x!n^x} e^{-\\lambda} = \\frac{\\lambda^x e^{-\\lambda}}{x!} \\lim_{n \\to \\infty} \\frac{n!}{(n-x)!n^x} = \\frac{\\lambda^x e^{-\\lambda}}{x!} \\lim_{n \\to \\infty} \\frac{n!}{(n-x)!} \\lim_{n \\to \\infty} \\frac{1}{n^x}$\n",
    "        - $\\lim_{n \\to \\infty} \\frac{n!}{(n-x)!} = \\lim_{n \\to \\infty} n^x$\n",
    "    - $= \\frac{\\lambda^x e^{-\\lambda}}{x!} \\lim_{n \\to \\infty} n^x \\lim_{n \\to \\infty} \\frac{1}{n^x} = \\frac{\\lambda^x e^{-\\lambda}}{x!} \\lim_{n \\to \\infty} \\frac{n^x}{n^x} = \\frac{\\lambda^x e^{-\\lambda}}{x!}$\n",
    "\n",
    "### Notation\n",
    "- $X \\sim Pois(\\lambda)$\n",
    "\n",
    "### Expected Value and Variance\n",
    "- (20) $E(X) = \\lambda$\n",
    "- (21) $Var(X) = \\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others\n",
    "There are many other discrete random variables. Here is a list of some other common ones and their purpose. You can look up their pmf, expected value, variance, etc.\n",
    "- Geometric\n",
    "    - Models the number of Bernoulli trials needed to reach the first success.\n",
    "- Negative Binomial\n",
    "    - Models the number of Bernoulli trials needed to reach r number of success.\n",
    "- Hypergeometric\n",
    "    - Models the number of successful draws from a population of size $N$ with $K$ number of objects of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equations\n",
    "Expected Value  \n",
    "1) $E(X) =\\mu= \\sum_x xP(X=x)$  \n",
    "2) $E(g(X)) = \\sum_x g(x)p(x)$  \n",
    "3) $E(c) = c$  \n",
    "4) $E(cX) = cE(X)$  \n",
    "5) $E(X + Y) = E(X) + E(Y)$  \n",
    "\n",
    "Variance  \n",
    "6) $Var(X) = E[(X - \\mu)^2]$   \n",
    "7) $Var(X) = E(X^2) - \\mu^2 = \\sum_x (x)^2p(x) - \\mu^2$  \n",
    "8) $Var(c) = 0$  \n",
    "9) $Var(X + c) = Var(X)$  \n",
    "10) $Var(aX) = a^2Var(X)$  \n",
    "11) $Var(X + Y) = Var(X) + Var(Y)$, if $X$ and $Y$ are independent  \n",
    "12) $Var(aX + bY) = a^2Var(X) + b^2Var(Y) + abCov(X, Y)$  \n",
    "\n",
    "Bernoulli  \n",
    "13) $p(x) = \\begin{cases} p, \\quad \\text{if }x=1 \\\\ 1-p, \\quad \\text{if }x=0 \\end{cases}$  \n",
    "14) $E(X) = p$  \n",
    "15) $Var(X) = p(1-p)$\n",
    "\n",
    "Binomial  \n",
    "16) $p(x) = \\binom n x p^x (1-p)^{n-x}$, for $n \\in \\mathbb{N}, \\quad p \\in [0,1], \\quad x \\in \\{0, 1, 2, ..., n\\} $  \n",
    "17) $E(X) = np$  \n",
    "18) $Var(X) = np(1-p)$\n",
    "\n",
    "Poisson  \n",
    "19) $p(x) = \\frac{\\lambda^x e^\\lambda}{x!}$, for $\\lambda >0, \\quad x \\in \\mathbb{N}$  \n",
    "20) $E(X) = \\lambda$  \n",
    "21) $Var(X) = \\lambda$  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}