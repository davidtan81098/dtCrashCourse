{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistics\n",
    "## Chapter 1.8 - Sampling Distribution\n",
    "Previous, we defined a statistic as a value computed from the data. A data point is a random variable. This means that a statistic is a function of random variables. In chapter 1.05, we showed that functions of random variables also have a probability distribution. Since a statistic has a probability distribution (called a sampling distribution), a statistic also a random variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Mean of a Normal Random Variable\n",
    "Suppose $Y_1, Y_2, ..., Y_n$ are samples from an iid normal distribution with mean $\\mu$ and variance $\\sigma^2$. The sample mean is normally distributed since it is a linear combination of normally distributed random variables.\n",
    "-  $\\bar Y = \\frac{1}{n}\\sum_{i=1}^n Y_i$\n",
    "\n",
    "The mean and variance of the sample mean is the following:\n",
    "- $E(\\bar Y) = \\mu$\n",
    "    - $E(\\bar Y) = E(\\frac{1}{n}\\sum_{i=1}^n Y_i) = \\frac{1}{n}E(\\sum_{i=1}^n Y_i) = \\frac{1}{n}\\sum_{i=1}^nE( Y_i) = \\frac{1}{n}\\sum_{i=1}^n\\mu = \\frac{1}{n}n\\mu = \\mu$\n",
    "- $Var(\\bar Y) = \\frac{\\sigma^2}{n}$\n",
    "    - $Var(\\bar Y) = Var(\\frac{1}{n}\\sum_{i=1}^n Y_i) = \\frac{1}{n^2}Var(\\sum_{i=1}^n Y_i) = \\frac{1}{n^2}\\sum_{i=1}^n Var(Y_i) = \\frac{1}{n^2}\\sum_{i=1}^n \\sigma^2 = \\frac{1}{n^2}n \\sigma^2 = \\frac{\\sigma^2}{n}$\n",
    "\n",
    "This can be rewritten as the following:\n",
    "- (1) $\\bar Y \\sim N(\\mu, \\frac{\\sigma^2}{n})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Variance of a Normal Random Variable\n",
    "Suppose $Y_1, Y_2, ..., Y_n$ are samples from an iid normal distribution with mean $\\mu$ and variance $\\sigma^2$. \n",
    "\n",
    "We know that the $\\chi^2 = \\sum_{i=1}^n X_i^2$, where $X_i$ are standard normals. That means we can use our samples to create a chi squared distribution by converting out samples into a standard normal.\n",
    "- $\\sum_{i=1}^n \\Big( \\frac{Y_i - \\mu}{\\sigma} \\Big)^2 \\sim \\chi^2_n$. \n",
    "\n",
    "We can factor out a $\\sigma^2$ from the summation because it is a constant.\n",
    "- $\\frac{1}{\\sigma^2}\\sum_{i=1}^n (Y_i - \\mu)^2 \\sim \\chi^2_n$\n",
    "\n",
    "Notice the summation looks very similar to the variance equation, $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n (Y_i - \\bar Y)^2$. We can replaced $\\mu$ with $\\bar Y$ and reduce the degree of freedom from the chi square distribution by 1.\n",
    "- $\\frac{1}{\\sigma^2}\\sum_{i=1}^n (Y_i - \\bar Y)^2 \\sim \\chi^2_{n-1}$\n",
    "\n",
    "Now we can replace the summation with the variance of the sample.\n",
    "- $\\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1}$\n",
    "\n",
    "We can interept this as the relationship between the sample variance and the population variance is a chi squared distribution and we can use this to make inference about the sample variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "The centeral limit theorem states for any random variable, $Y$, with mean $\\mu$ and a finite variance $\\sigma^2$, the sample mean $\\bar Y$ will converge to $N(\\mu, \\frac{\\sigma^2}{n})$ as the sample size $n$ approach $\\infty$. This means that with a large enough sample ($n \\ge 30$, commonly stated number, not necessarily always true), the sample mean is approximately normally distributed and we can make inferences about the mean of (almost) any distribution. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}