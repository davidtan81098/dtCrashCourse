{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Introduction to Statistics\n",
    "\n",
    "## Chapter 2.2 - Confidence Interval\n",
    "Point estimates are a great way of estimating a parameter, but chances are the estimate does not equal the true parameter. An interval estimate of a parameter, more commonly known as confidence interval or CI, gives us a range of values of where we think the true parameter may be. The interval also has a probability of containing the true parameter. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Main Concept\n",
    "\n",
    "Assume that we are trying to find an estimator for $\\theta$. We know that the estimator $\\hat\\theta$ will follow a sampling distribution of some kind with the expected value of $\\theta$. However, the $\\hat\\theta$ we just calculated is a single observation and we do not know where it is along the distribution. Theoretically, the difference between $\\theta$ and $\\hat\\theta$ is $\\pm\\infty$, or whatever the maximum/ minimum is allowed by the distribution. Ideally, we can provide an upper and lower bound to what $\\theta$ likely is based on $\\hat\\theta$. \n",
    "\n",
    "The goal is to create the following statement:  \n",
    "$P(\\hat L\\le \\theta \\le \\hat U) = 1 - \\alpha$  \n",
    "where $\\hat L, \\hat U$ is lower and upper bounds derived from $\\hat\\theta$, and $1 - \\alpha$ is the confidence coefficient. $\\alpha$ can be thought of as error rate.\n",
    "\n",
    "Typically, we set $\\alpha$ to 5% or 1% (95% or 99%  confidence interval), however this is arbitrary.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Calculating CI\n",
    "Most of the times, the parameter you need a confidence interval for has a known distribution. This may be because it is a summary statistic with a known sampling distribution, from a large sample MLE (they are asymptotically normal), etc. \n",
    "\n",
    "### Known Distribution - Normal\n",
    "Many times, the parameter is from a normal distribution. Suppose we are trying to find the CI for $\\hat\\theta$ and $\\hat\\theta \\sim N(\\mu, \\sigma^2)$. If we convert this to the standard normal, then $\\frac{\\hat\\theta-\\mu}{\\sigma^2} \\sim N(0,1)$. Then we can write the following probability statement:  \n",
    "$P(z_1 \\le \\frac{\\hat\\theta-\\mu}{\\sigma^2} \\le z_2) = 1-\\alpha$, where $z_1, z_2$ are constants chosen based on the standard normal.  \n",
    "We can rearrange the equation into:  \n",
    "$P(\\hat\\theta + z_2\\sigma^2 \\le \\mu \\le \\hat\\theta + z_1\\sigma^2) = 1-\\alpha $  \n",
    "Based on this, we know the confidence interval for a normally distributed parameter is of the form $(\\hat\\theta + z_2\\sigma^2, \\hat\\theta + z_1\\sigma^2)$.\n",
    "\n",
    "If $\\sigma^2 $ is unknown, we would use sample variance $S^2$ instead. And we may decide to use the Student T distribution instead of the normal distribution.\n",
    "\n",
    "### Known Distribution - Chi squared\n",
    "Other times, the parameter is from a chi squared distribution, e.i. sample variance. The CI for sample variance can be derived from a vary similar process. We know that $\\frac{(n-1)S^2}{\\sigma^2} \\sim X^2_{n-1}$. We can write the following probability statement:  \n",
    "$P\\Big(c_1 \\le \\frac{(n-1)S^2}{\\sigma^2} \\le c_2\\Big) = 1-\\alpha$ where $c_1, c_2$ are constants chosen based on the chi squared distribution with $n-1$ degrees of freedom.\n",
    "We can rearrange the equation into:  \n",
    "$P\\Big(\\frac{(n-1)S^2}{c_2} \\le \\sigma^2 \\le \\frac{(n-1)S^2}{c_1}\\Big) = 1-\\alpha $  \n",
    "Based on this, we know the confidence interval for a chi squared distributed parameter is of the form $\\Big(\\frac{(n-1)S^2}{c_2}, \\frac{(n-1)S^2}{c_1}\\Big)$.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Unknown Distribution - Bootstrap\n",
    "Not all summary statistic has a known distribution, such as median. If we do not know the distribution of the parameter $\\theta$, then we are unable to derive the confidence interval using $\\hat\\theta$. Normally, we use $\\hat\\theta$ to make an inference about $\\theta$. Instead, we will model the behavior of $\\hat\\theta$ by using a resampling technique called Bootstrap, and use the model to make a interfences about $\\theta$.\n",
    "\n",
    "We model the behavior $\\hat\\theta$, i.e. finding the distribution, by creating a histogram. Typically, we make histograms by calculating same statistic from a samples from the popultion, then plotting the frequency. In this case, we need to calculate many $\\hat\\theta'$ and plot the frequency of those in order to create the histogram. Suppose $\\hat\\theta$ was calculated using a sample of 40 observations. This will be our \"popultion\" that we will \"sample\" from. We will need to sample 40 observations from our popultion, so the variance of $\\hat\\theta$ will be the same as the variance of $\\hat\\theta'$. Notice, if we sample 40 observations from a popultion of 40, then there will be no variability. To introduce variability, we will sample with replacement. Now that we have our new sample, we can calculate $\\hat\\theta'$ from the sample. After this process is repeated many times (50-100+ times), then we can create a histogram of $\\hat\\theta'$. We can find the 2.5 percentile and the 97.5 percentile and use those are the lower and upper bounds for the 95% confidence interval. The estimate will be more accurate the more we resample it, however, we should have a fairly good estimate at 50 samples and there will be minimal improvement after 100 samples.\n",
    "\n",
    "This technique can also be used to find any other property of a statistic, such as bias, variance, etc."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Interpretation\n",
    "\n",
    "When we calculate a 95% confidence interval, it means that the procedure used to generate the interval has 95% probability of containing the true parameter within the interval. Do not interpret it as 95% of the times, the true parameter is will in the interval you just calculated. This implying the true parameter changes over time, and it will be within the confidence interval 95% of the times. The true value of the parameter does not change. That means once the confidence interval is generated, it either contains or does not contain the true parameter.\n",
    "\n",
    "Another way to view this, is that if you generate many, many confidence intervals, then 95% of them will contain the true parameter. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}